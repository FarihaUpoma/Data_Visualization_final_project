{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "VNc_uLTO7Id7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorview in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (0.4.1)\n",
      "Requirement already satisfied: linora>=0.9.3 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from tensorview) (0.10.0)\n",
      "Requirement already satisfied: pandas>=0.24.1 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from tensorview) (1.1.4)\n",
      "Requirement already satisfied: matplotlib in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from tensorview) (3.3.3)\n",
      "Requirement already satisfied: pyecharts-snapshot>=0.1.10tensorflow>=2.0.0 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from tensorview) (0.2.0)\n",
      "Requirement already satisfied: pyecharts>=1.2.0 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from tensorview) (1.9.0)\n",
      "Requirement already satisfied: colorlog>=4.6.2 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from linora>=0.9.3->tensorview) (4.7.2)\n",
      "Requirement already satisfied: pillow>=8.0.1 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from linora>=0.9.3->tensorview) (8.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from pandas>=0.24.1->tensorview) (2020.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from pandas>=0.24.1->tensorview) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from pandas>=0.24.1->tensorview) (1.19.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from matplotlib->tensorview) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from matplotlib->tensorview) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from matplotlib->tensorview) (2.4.7)\n",
      "Requirement already satisfied: pyppeteer>=0.0.25 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from pyecharts-snapshot>=0.1.10tensorflow>=2.0.0->tensorview) (0.2.5)\n",
      "Requirement already satisfied: prettytable in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from pyecharts>=1.2.0->tensorview) (2.1.0)\n",
      "Requirement already satisfied: simplejson in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from pyecharts>=1.2.0->tensorview) (3.17.2)\n",
      "Requirement already satisfied: jinja2 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from pyecharts>=1.2.0->tensorview) (2.11.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.1->tensorview) (1.15.0)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from pyppeteer>=0.0.25->pyecharts-snapshot>=0.1.10tensorflow>=2.0.0->tensorview) (1.4.4)\n",
      "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from pyppeteer>=0.0.25->pyecharts-snapshot>=0.1.10tensorflow>=2.0.0->tensorview) (8.1.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from pyppeteer>=0.0.25->pyecharts-snapshot>=0.1.10tensorflow>=2.0.0->tensorview) (1.26.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from pyppeteer>=0.0.25->pyecharts-snapshot>=0.1.10tensorflow>=2.0.0->tensorview) (4.54.1)\n",
      "Requirement already satisfied: websockets<9.0,>=8.1 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from pyppeteer>=0.0.25->pyecharts-snapshot>=0.1.10tensorflow>=2.0.0->tensorview) (8.1)\n",
      "Requirement already satisfied: wcwidth in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from prettytable->pyecharts>=1.2.0->tensorview) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/ashik/opt/anaconda3/envs/smm/lib/python3.8/site-packages (from jinja2->pyecharts>=1.2.0->tensorview) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "! pip install tensorview\n",
    "import tensorview as tv\n",
    "\n",
    "\n",
    "import linora as la\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ESmj0i5l7XbD"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "v2oLCb847c9a"
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH=200\n",
    "IMG_HEIGHT=200\n",
    "img_folder='data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JRWBHBrR7IeC"
   },
   "outputs": [],
   "source": [
    "def create_dataset(img_folder):\n",
    "    file_count=0\n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "    \n",
    "\n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "            #print(file)\n",
    "            file_count+=1\n",
    "            #print(file_count)\n",
    "            image_path= os.path.join(img_folder, dir1,  file)\n",
    "            image= cv2.imread( image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image=np.array(image)\n",
    "            image = image.astype('float32')\n",
    "            image /= 255 \n",
    "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "            img_data_array.append(image)\n",
    "            if dir1=='covid':\n",
    "                class_name.append(1)\n",
    "            else:\n",
    "                class_name.append(0)\n",
    "            \n",
    "    return img_data_array, class_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WMC1XIPXYl3"
   },
   "source": [
    "Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8ZrpwxQlXFIV"
   },
   "outputs": [],
   "source": [
    "X, y = create_dataset(img_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AWGyur5TR3MC"
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MqAmfgx0Oi6T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (37, 200, 200)\n",
      "37 train samples\n",
      "19 test samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LPMQAHfA7IeD"
   },
   "outputs": [],
   "source": [
    "\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same',input_shape=(200,200,1)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "# model.add(layers.Dense(2,activation='softmax'))\n",
    "\n",
    "input_layer = tf.keras.Input(shape=(200, 200, 1))\n",
    "x = tf.keras.layers.Conv2D(64, 3)(input_layer)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.MaxPool2D(2)(x)\n",
    "x = tf.keras.layers.Conv2D(64, 3)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "output_layer = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "model = tf.keras.Model(input_layer, output_layer)\n",
    "model.compile(loss=['sparse_categorical_crossentropy'], \n",
    "                optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.0001,)\n",
    "# model.compile(optimizer=opt,\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(train_data,train_labels, batch_size=4,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i03_yzqtPc67"
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='loss', verbose=1,\n",
    "    save_best_only=True, save_weights_only=True, mode='auto', save_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTPLfGLmPU4j"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 16\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i78rKiF_Tili"
   },
   "outputs": [],
   "source": [
    "model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r2-itQqmbsTy",
    "outputId": "c541beaf-c5b3-4234-b72a-36adc003119a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/batch_normalization_2/batch_normalization_2/beta:0\n",
      "/batch_normalization_2/batch_normalization_2/gamma:0\n",
      "/batch_normalization_2/batch_normalization_2/moving_mean:0\n",
      "/batch_normalization_2/batch_normalization_2/moving_variance:0\n",
      "/batch_normalization_3/batch_normalization_3/beta:0\n",
      "/batch_normalization_3/batch_normalization_3/gamma:0\n",
      "/batch_normalization_3/batch_normalization_3/moving_mean:0\n",
      "/batch_normalization_3/batch_normalization_3/moving_variance:0\n",
      "/conv2d_2/conv2d_2/bias:0\n",
      "/conv2d_2/conv2d_2/kernel:0\n",
      "/conv2d_3/conv2d_3/bias:0\n",
      "/conv2d_3/conv2d_3/kernel:0\n",
      "/dense_1/dense_1/bias:0\n",
      "/dense_1/dense_1/kernel:0\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "keys = []\n",
    "final_keys = []\n",
    "f = h5py.File(\"weights.h5\",'r')\n",
    "\n",
    "# with h5py.File(\"weights.h5\",'r') as f: # open file\n",
    "f.visit(keys.append) # append all keys to list\n",
    "for key in keys:\n",
    "    if ':' in key: # contains data if ':' in key\n",
    "        print(f[key].name)\n",
    "        final_keys.append(f[key].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LOydfBYPjTq7"
   },
   "outputs": [],
   "source": [
    "group = f[key]\n",
    "\n",
    "for i in final_keys:\n",
    "    print(i)\n",
    "    print(group[i][()].shape)\n",
    "    print(group[i][()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7naVCaEPIGgU"
   },
   "outputs": [],
   "source": [
    "weights_dict = {}\n",
    "\n",
    "weight_callback = tf.keras.callbacks.LambdaCallback \\\n",
    "( on_epoch_end=lambda epoch, logs: weights_dict.update({epoch:model.get_weights()}))\n",
    "\n",
    "history = model.fit( X_train, y_train, batch_size=8, epochs=5, callbacks=[weight_callback] )\n",
    "\n",
    "# retrive weights\n",
    "for epoch,weights in weights_dict.items():\n",
    "    print(\"Weights for 2nd Layer of epoch #\",epoch+1)\n",
    "    print(weights[2])\n",
    "    print(\"Bias for 2nd Layer of epoch #\",epoch+1)\n",
    "    print(weights[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amwSejkA-3eO"
   },
   "outputs": [],
   "source": [
    "len(weights_dict[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "d9wQToNHob4H"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "log_file = {}\n",
    "weight_callback = tf.keras.callbacks.LambdaCallback \\\n",
    "( on_epoch_end=lambda epoch, logs: weights_dict.update({epoch:model.get_weights()}))\n",
    "\n",
    "json_log = open('loss_log.json', mode='wt', buffering=1)\n",
    "json_logging_callback = tf.keras.callbacks.LambdaCallback(\n",
    "            on_epoch_end=lambda epoch, \n",
    "            # logs: json_log.write(\n",
    "            #     json.dumps({'epoch': epoch, \n",
    "            #                 'loss': logs['loss'],\n",
    "            #                 'weights': model.get_weights()}) + '\\n'),\n",
    "            logs: log_file.update({\n",
    "                epoch: {\n",
    "                    'epoch': epoch,\n",
    "                    'loss' : logs['loss'],\n",
    "                    'weights': model.get_weights()\n",
    "                }\n",
    "            }),\n",
    "            on_train_end=lambda logs: json_log.close()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C7sW5RJIofx5",
    "outputId": "bf408015-840e-4ddf-e7dd-b566d3648813",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5/5 [==============================] - 2s 492ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.5881 - val_accuracy: 0.8421\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 2s 452ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0156 - val_accuracy: 0.7368\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 2s 456ms/step - loss: 2.1568e-05 - accuracy: 1.0000 - val_loss: 4.2472 - val_accuracy: 0.7368\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 2s 468ms/step - loss: 1.2196 - accuracy: 0.9730 - val_loss: 1.1135 - val_accuracy: 0.8421\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 2s 441ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.8834 - val_accuracy: 0.4737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcf0db66100>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "epochs = 5\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "\n",
    "          callbacks=[json_logging_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_weights = []\n",
    "filter_weights_df = pd.DataFrame()\n",
    "index = 0\n",
    "for i in range(len(log_file[0]['weights'][0])):\n",
    "    for j in range(len(log_file[0]['weights'][0][i])):\n",
    "        filter_weights.append(log_file[0]['weights'][0][i][j][0])\n",
    "        filter_weights_df[index] = log_file[0]['weights'][0][i][j][0]\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_weights_df.to_csv('filter_weights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "filter_weights = min_max_scaler.fit_transform(filter_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.823784</td>\n",
       "      <td>0.534068</td>\n",
       "      <td>0.328726</td>\n",
       "      <td>0.835604</td>\n",
       "      <td>0.055848</td>\n",
       "      <td>0.120485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100255</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.457018</td>\n",
       "      <td>0.417920</td>\n",
       "      <td>0.162308</td>\n",
       "      <td>0.136650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.537630</td>\n",
       "      <td>0.834499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202147</td>\n",
       "      <td>0.733210</td>\n",
       "      <td>0.920442</td>\n",
       "      <td>0.278218</td>\n",
       "      <td>0.580191</td>\n",
       "      <td>0.846649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.699194</td>\n",
       "      <td>0.941569</td>\n",
       "      <td>0.168110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101424</td>\n",
       "      <td>0.398990</td>\n",
       "      <td>0.148570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086521</td>\n",
       "      <td>0.466877</td>\n",
       "      <td>0.227804</td>\n",
       "      <td>0.334362</td>\n",
       "      <td>0.493192</td>\n",
       "      <td>0.234109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.562838</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.604131</td>\n",
       "      <td>0.433610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.308819</td>\n",
       "      <td>0.242385</td>\n",
       "      <td>0.118685</td>\n",
       "      <td>0.663894</td>\n",
       "      <td>0.542264</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577829</td>\n",
       "      <td>0.345768</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875258</td>\n",
       "      <td>0.336921</td>\n",
       "      <td>0.279481</td>\n",
       "      <td>0.305051</td>\n",
       "      <td>0.038248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.494332</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636952</td>\n",
       "      <td>0.241384</td>\n",
       "      <td>0.247687</td>\n",
       "      <td>0.053938</td>\n",
       "      <td>0.972070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.737442</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>0.371387</td>\n",
       "      <td>0.764259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359803</td>\n",
       "      <td>0.990279</td>\n",
       "      <td>0.605293</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878686</td>\n",
       "      <td>0.525334</td>\n",
       "      <td>0.436971</td>\n",
       "      <td>0.579348</td>\n",
       "      <td>0.677001</td>\n",
       "      <td>0.301860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.823784  0.534068  0.328726  0.835604  0.055848  0.120485  0.000000   \n",
       "1   0.457018  0.417920  0.162308  0.136650  1.000000  0.938431  0.000000   \n",
       "2   0.000000  0.459676  1.000000  0.202147  0.733210  0.920442  0.278218   \n",
       "3   0.699194  0.941569  0.168110  0.000000  0.075146  1.000000  0.101424   \n",
       "4   0.086521  0.466877  0.227804  0.334362  0.493192  0.234109  0.000000   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "59  0.604131  0.433610  0.000000  0.308819  0.242385  0.118685  0.663894   \n",
       "60  0.000000  0.577829  0.345768  1.000000  0.875258  0.336921  0.279481   \n",
       "61  0.000000  0.494332  0.280982  1.000000  0.636952  0.241384  0.247687   \n",
       "62  0.737442  0.150235  0.371387  0.764259  0.000000  0.359803  0.990279   \n",
       "63  1.000000  0.878686  0.525334  0.436971  0.579348  0.677001  0.301860   \n",
       "\n",
       "           7         8  \n",
       "0   0.100255  1.000000  \n",
       "1   0.537630  0.834499  \n",
       "2   0.580191  0.846649  \n",
       "3   0.398990  0.148570  \n",
       "4   0.562838  1.000000  \n",
       "..       ...       ...  \n",
       "59  0.542264  1.000000  \n",
       "60  0.305051  0.038248  \n",
       "61  0.053938  0.972070  \n",
       "62  0.605293  1.000000  \n",
       "63  0.000000  0.527123  \n",
       "\n",
       "[64 rows x 9 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_weights_df = pd.DataFrame(filter_weights.transpose())\n",
    "filter_weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "K2Zlf2Wy5mFm"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "w = csv.writer(open(\"output.csv\", \"w\"))\n",
    "for key, val in log_file.items():\n",
    "    w.writerow([key, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jD0PRGZi7IeF"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(our_data, columns=['loss', 'acc'])\n",
    "df.to_csv('loss_acc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "za-1AnGvYIm2",
    "outputId": "a5569328-9df4-4c46-e735-f62bca51e256"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "            .fl-table {\n",
       "                margin: 20px;\n",
       "                border-radius: 5px;\n",
       "                font-size: 12px;\n",
       "                border: none;\n",
       "                border-collapse: collapse;\n",
       "                max-width: 100%;\n",
       "                white-space: nowrap;\n",
       "                word-break: keep-all;\n",
       "            }\n",
       "\n",
       "            .fl-table th {\n",
       "                text-align: left;\n",
       "                font-size: 20px;\n",
       "            }\n",
       "\n",
       "            .fl-table tr {\n",
       "                display: table-row;\n",
       "                vertical-align: inherit;\n",
       "                border-color: inherit;\n",
       "            }\n",
       "\n",
       "            .fl-table tr:hover td {\n",
       "                background: #00d1b2;\n",
       "                color: #F8F8F8;\n",
       "            }\n",
       "\n",
       "            .fl-table td, .fl-table th {\n",
       "                border-style: none;\n",
       "                border-top: 1px solid #dbdbdb;\n",
       "                border-left: 1px solid #dbdbdb;\n",
       "                border-bottom: 3px solid #dbdbdb;\n",
       "                border-right: 1px solid #dbdbdb;\n",
       "                padding: .5em .55em;\n",
       "                font-size: 15px;\n",
       "            }\n",
       "\n",
       "            .fl-table td {\n",
       "                border-style: none;\n",
       "                font-size: 15px;\n",
       "                vertical-align: center;\n",
       "                border-bottom: 1px solid #dbdbdb;\n",
       "                border-left: 1px solid #dbdbdb;\n",
       "                border-right: 1px solid #dbdbdb;\n",
       "                height: 30px;\n",
       "            }\n",
       "\n",
       "            .fl-table tr:nth-child(even) {\n",
       "                background: #F8F8F8;\n",
       "            }\n",
       "        </style>\n",
       "        <div id=\"86870bcfc2474039b2fe749569b4dd06\" class=\"chart-container\" style=\"\">\n",
       "            <p class=\"title\" style=\"font-size: 18px; font-weight:bold;\" > Model Summary</p>\n",
       "            <p class=\"subtitle\" style=\"font-size: 12px;\" > </p>\n",
       "            <table class=\"fl-table\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th></th>\n",
       "            <th>layer_custom_name</th>\n",
       "            <th>layer_object_name</th>\n",
       "            <th>trainable</th>\n",
       "            <th>dtype</th>\n",
       "            <th>input_shape</th>\n",
       "            <th>output_shape</th>\n",
       "            <th>params</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>0</td>\n",
       "            <td>input_1</td>\n",
       "            <td>InputLayer</td>\n",
       "            <td>True</td>\n",
       "            <td>float32</td>\n",
       "            <td>[(None, 200, 200, 1)]</td>\n",
       "            <td>[(None, 200, 200, 1)]</td>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1</td>\n",
       "            <td>conv2d</td>\n",
       "            <td>Conv2D</td>\n",
       "            <td>True</td>\n",
       "            <td>float32</td>\n",
       "            <td>(None, 200, 200, 1)</td>\n",
       "            <td>(None, 198, 198, 64)</td>\n",
       "            <td>640</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2</td>\n",
       "            <td>batch_normalization</td>\n",
       "            <td>BatchNormalization</td>\n",
       "            <td>True</td>\n",
       "            <td>float32</td>\n",
       "            <td>(None, 198, 198, 64)</td>\n",
       "            <td>(None, 198, 198, 64)</td>\n",
       "            <td>256</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3</td>\n",
       "            <td>re_lu</td>\n",
       "            <td>ReLU</td>\n",
       "            <td>True</td>\n",
       "            <td>float32</td>\n",
       "            <td>(None, 198, 198, 64)</td>\n",
       "            <td>(None, 198, 198, 64)</td>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4</td>\n",
       "            <td>max_pooling2d</td>\n",
       "            <td>MaxPooling2D</td>\n",
       "            <td>True</td>\n",
       "            <td>float32</td>\n",
       "            <td>(None, 198, 198, 64)</td>\n",
       "            <td>(None, 99, 99, 64)</td>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5</td>\n",
       "            <td>conv2d_1</td>\n",
       "            <td>Conv2D</td>\n",
       "            <td>True</td>\n",
       "            <td>float32</td>\n",
       "            <td>(None, 99, 99, 64)</td>\n",
       "            <td>(None, 97, 97, 64)</td>\n",
       "            <td>36928</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>6</td>\n",
       "            <td>batch_normalization_1</td>\n",
       "            <td>BatchNormalization</td>\n",
       "            <td>True</td>\n",
       "            <td>float32</td>\n",
       "            <td>(None, 97, 97, 64)</td>\n",
       "            <td>(None, 97, 97, 64)</td>\n",
       "            <td>256</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>7</td>\n",
       "            <td>re_lu_1</td>\n",
       "            <td>ReLU</td>\n",
       "            <td>True</td>\n",
       "            <td>float32</td>\n",
       "            <td>(None, 97, 97, 64)</td>\n",
       "            <td>(None, 97, 97, 64)</td>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>8</td>\n",
       "            <td>flatten</td>\n",
       "            <td>Flatten</td>\n",
       "            <td>True</td>\n",
       "            <td>float32</td>\n",
       "            <td>(None, 97, 97, 64)</td>\n",
       "            <td>(None, 602176)</td>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>9</td>\n",
       "            <td>dense</td>\n",
       "            <td>Dense</td>\n",
       "            <td>True</td>\n",
       "            <td>float32</td>\n",
       "            <td>(None, 602176)</td>\n",
       "            <td>(None, 2)</td>\n",
       "            <td>1204354</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>total</td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td>1242434</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "\n"
      ],
      "text/plain": [
       "<pyecharts.render.display.HTML at 0x7fcf6dc25e20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv.model.statistics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "fxalhuQFZuFn",
    "outputId": "bf805d94-1c61-474c-9885-9963dcaff74e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ashik/Documents/Courses/Spring 2021/Data visualization/Final project/visualize_weights.html'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv.model.visualize_weights(model, layer_name=['conv2d', 'batch_normalization', 'conv2d_1', 'batch_normalization_1' 'dense'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxt-h0rxCVrn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
